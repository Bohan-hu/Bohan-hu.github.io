[{"title":"几种寄存器重命名技术","date":"2019-09-24T19:45:28.000Z","path":"2019/09/24/Register_rename/","text":"第七章：寄存器重命名7.1 概述 数据相关性中，只有RAW是真相关，其他的可以通过不同的寄存器名字解决 WAW相关 1R1 &#x3D; R2 + R32R1 &#x3D; R4 * R5 可以改为 1R1 &#x3D; R2 + R32R6 &#x3D; R4 * R5 WAR相关 1R1 &#x3D; R2 * R32R2 &#x3D; R4 + R5 可以改为 1R1 &#x3D; R2 * R32R6 &#x3D; R4 + R5 寄存器重命名的原因 个数有限 程序中的循环体：不断地向某个寄存器写入，会导致大量WAW相关 代码重用：一段代码被重复调用，导致WAW相关 动态的寄存器重命名，消除WAW和WAR冒险。 重命名映射表可以通过SRAM或CAM来实现。 7.2 寄存器重命名的方式（1）将逻辑寄存器ARF扩展来实现重命名 （2）使用统一的物理寄存器PRF来实现重命名 （3）使用ROB来实现重命名 三种方法的本质都是把逻辑寄存器映射到物理寄存器上面。 设计考虑的问题 （1）什么时候占用物理寄存器？寄存器来自哪里？ （2）什么时候释放物理寄存器？寄存器去向何处？ （3）分支预测失败，如何处理？ （4）发生异常，如何处理？ 7.2.1 使用ROB进行寄存器重命名 当一条指令被写入ROB一个项时，这个项在ROB中的编号就是这条指令的目的寄存器对应的物理寄存器。（映射关系） 逻辑寄存器中存的是最新的值 还需要一个映射表来判断当前ARF的值是否最新，应该从ARF中取值还是从PRF中取值？（如果ROB中有写R1的指令，那么就需要从ROB中找到R1的值，因为此时ARF中的值不是最新的） 如果一个逻辑寄存器的值还在ROB中，则RRT会给出这个寄存器在ROB中的编号 如果指令提交，则这一项会被标记 缺点：增加了ROB读的复杂性，且操作数可能来自ROB，也可能来自ARF 7.2.2 将ARF扩展进行寄存器重命名引入PRF（FIFO），当指令要写寄存器时，分配一个项，在映射表中记录地址，当指令要提交时，则释放在FIFO中的空间，并写回ARF。 也需要一个映射表。 一个逻辑寄存器的值在其生命周期内，仍然可能存在于PRF与ARF两个地方。 7.2.3 使用统一PRF进行寄存器重命名 1567606936444 PRF中存储了所有推测的(speculative)和正确的(retire)的寄存器值 物理寄存器的个数多于指令集中定义的逻辑寄存器的个数 在PRF中 没有和指令产生映射关系的寄存器：Free 使用一个Free list来记录哪些寄存器空闲 若一条指令被寄存器重命名，且存在目的寄存器，就会占据PRF中的一个寄存器，就不在Free list里了 被占用的寄存器有3个不同状态 值未计算出来 值计算出来了，但没有提交 已经提交 需要一个映射表，存储逻辑寄存器映射到物理寄存器的关系 Free List可以用FIFO实现（四端口，因为要取出4条指令，最多要重命名4个目的寄存器） 在寄存器重命名阶段（此时不考虑存在相关性问题） 源寄存器：查映射表，得到真实地址 目的寄存器：查Free List，进行重命名 一条指令只有在retire（提交）后，才可以被外部看到，才是正确的 需要使用另外一个RAT，用以存储已经提交的指令和物理寄存器之间的关系！ 这个在后面的寄存器重命名恢复过程中，会用得到 提交的时候写这个RAT，称为Architectural RAT 重命名时，读取的RAT时Speculative RAT，因为Spec RAT是最新的，考虑到所有正在执行的指令 一个物理寄存器不再被后面指令使用时，就变成空闲状态，但如何才能知道后续指令是否还会使用这个物理寄存器呢？？ 之前的理解错误，认为只要提交了指令，就可以释放这个物理寄存器。 一个保守的方法：相同的逻辑寄存器被再次写入 指令b对r1进行再次写入，则指令b对应的p6将替代p1，p1可以被释放 因此，还需要存储它之前对应的物理存储器（之前普林斯顿课上的Previous preg) 7.3 重命名映射表重命名映射表（RAT）在实现层面上，有2中方式。一种是基于SRAM，一种是基于CAM。 基于SRAM的需要多端口（或者直接使用寄存器） 例如，有32个ARF，有64个PRF，就需要32*6bits大小的寄存器 使用ARF编号寻址PRF内容（ARF编号作为地址） 基于CAM的映射表 大小等于物理寄存器的个数 每个表项都存放逻辑寄存器的编号 有点类似于全相联 有Valid bit，比较方便用于CheckPoint的记录（相比SRAM） 使用ARF编号作为内容寻址PRF 在分支指令时，需要保存CheckPoint，对SRAM来说，相当于需要保存所有的寄存器，而对于CAM而言，只需要将V往右进行移位就可以了 基于CAM的映射表仍然需要一个free list来记录哪些物理寄存器是空闲的 一个物理寄存器何时空闲？后续指令写入同一逻辑寄存器（pPreg[a] = preg[b])，此时就可以释放之前对应的物理寄存器 并不是有效位V为0就代表是空闲状态，有可能映射关系刚刚被覆盖 空闲状态的管理不需要cRAT的参与 实例：使用CAM做寄存器重命名 （1）在分支指令F进行寄存器重命名时，需要对cRAT进行Checkpoint的保存，此时cRAT的内容如下表所示。 1567847588448 指令BDE都写寄存器r7，对每条指令的r7进行重命名。 在指令E进行寄存器重命名之后，物理寄存器P14就建立了和r7的对应关系，之前的2个映射关系全部无效（但不意味着这个物理寄存器现在空闲——如何理解？为什么不能用？P208一段话） 同时，有效位V全部被右移到了GC0进行备份 （2）F执行完之后，发现分支预测错误 1567848498900 在对cRAT进行恢复之前，状态如上表所示。 指令H重命名了r7，上面指令E对应的映射关系失效 分支指令F在预测失败后，进行状态恢复，将GC0的内容写到cRAT的有效位V，此时cRAT恢复到分支指令F进行寄存器重命名之前的状态。 指令B所占据的表项可能已经空闲，甚至被后续指令使用，但是恢复后，有效位变成了0. 理论上，有几个checkpoint，就能允许有几条分支指令存在于流水线中。 实例2：两条分支指令的情况： 第一条分支指令D对寄存器进行重命名时，保存状态到GC0 其中，A的重命名映射关系被覆盖，此时V变成了0 第二条分支指令G进行寄存器重命名时，继续对状态进行保存。此前，r9寄存器被重新命名了2次，导致E对应的映射关系被覆盖。 1567941425630 指令进行寄存器重命名完毕后，状态如下表所示：最后的HIJ指令覆盖了所有的映射关系 1567941591354 此时，如果发现分支指令D预测错误，需要使用GC0对cRAT进行恢复，还要对free list进行恢复（读指针），并且清除此后所有的GC （这个方法比较复杂，可以之后再研究，此时可以先弄清楚基于SRAM的重命名方式） 7.4 超标量处理器的寄存器重命名一般步骤对于Dest = Src1 op Src2的而言， （1）从RAT中找到两个Src对应的物理寄存器PSrc（不同的扩展方式有不同的找法） （2）从Free List中找到一个空闲的物理寄存器Pdest，作为指令的目的寄存器 （3）将逻辑寄存器Dest和物理寄存器PDest的映射关系写入重命名映射表RAT中。这样，使用Dest作为源寄存器的指令就可以正确寻址了。 对应4 way超标量处理器而言，每周期对4条指令进行寄存器重命名。每条指令需要使用RAT的三个读端口，4条指令需要使用RAT的12个读端口，每条指令需要使用RAT的一个写端口 同时重命名带来的相关性问题还要考虑每个周期同时进行寄存器重命名的多条指令之间的相关性。 由于这四条指令是同时进行寄存器重命名的，会从RAT里读取信息，这样会造成错误的重命名，获取错误的数据。 （1）AB之间存在RAW相关，要先重命名r0，再从RAT读取r0对应的PR，不能同时 （2）ABD之间存在WAW，而再ROB中有保存指令对应的旧的映射关系，以方便指令退休时对旧的映射关系进行释放，因此，在记录旧的映射关系时，需要使用之前和他存在WAW相关的指令的映射关系，而不是从RAT读取的映射关系。例如，指令B将r0重命名为P31，旧的映射关系应该为P30，而不是从RAT读出的结果，由于几条指令是同时进行寄存器重命名的，所以需要注意这点。 （3）BD之间存在WAR相关，指令B读取r0，指令D写r0，这问题不大。 在超标量处理器设计中，寄存器重命名占用了大量的延迟，第一是SRAM多端口的延迟，第二是相关性处理造成的延迟。 像这种情况，对于指令ABD存在的相关性问题，在下面的解决中，只允许指令D写入映射表，那指令A和B怎么办？指令B的源操作数是指令A的目的操作数，而指令A的映射关系又被指令D覆盖了。这是个问题吗？ 第一步：读出原有的映射关系，这里指的是操作数原有的映射关系和目的寄存器原有的映射关系，这个映射关系位于，在上面的指令序列中，以第一条指令A为例，读出r0, r1, r2之前对应的物理寄存器，读出r0对应的物理寄存器是为了之后提交后能够释放原来的物理寄存器进入Free List。读出r1, r2的对应关系是为了从物理寄存器堆中取操作数。这一步是并行发生的，存在的问题可能就是在指令AB中存在RAW冒险，此时，需要采用给r0新分配的物理寄存器号P30，而不是原有的映射关系（原有的r0映射关系已经无效了，在后面会被覆盖，所以不能用） 第二步：解决WAW冒险。通过寄存器重命名，我们解决了WAW冒险，下一步修改RAT时，应该以最新的映射关系为准，也就是r0映射到P33。注意，这一步是为之后的指令服务的。在前面的几条指令中，r0被分别映射到了P30和P31，这个关系并没有在RAT中记录，因为我们已经读完了RAT，源操作数信息（对应的物理寄存器）已经就绪；写RAT，是为了后面的指令服务，这四条指令将不再读RAT的内容。 值得注意的是，指令AB中r0的映射关系不在RAT中记录，但是会在ROB中记录，在提交指令时，P30、P31会被逐个释放到自由列表。 7.4.1 解决RAW相关性（读原有的映射关系） 这一步主要是读出原有的映射关系 如果存在新分配的 上图表示的是不存在RAW相关性的寄存器重命名过程，而下图展示的是存在RAW相关性，但没有进行处理时，寄存器的重命名过程。 在寄存器重命名阶段，指令的顺序还是in-order的，需要把每一条指令的源寄存器编号和前面所有指令的目的寄存器编号进行比较，如果存在一个相等的项，就从当前周期的Free List输出对应值，如果存在多个相等的项，就选择最新的那条指令。 1567945429229 组内相关性检查的电路和访问RAT是并行工作的，不会对处理器的周期产生负面影响。 越后面的指令，需要的比较就越多。 7.4.2 解决WAW相关性（写入）WAW相关性虽然对执行过程没有什么影响，但是对后续的ROB写入和寄存器的释放有影响。 对写RAT进行检查 在重命名这个周期内，如果有多条指令的目的寄存器都相等，只有最新的映射关系才允许写入RAT。 设置一个写使能信号：是否更新RAT？由于后续指令可能会覆盖，所以只允许一组存在WAW相关的指令中，最新的指令更新 和上面相反的是，越靠前的指令需要检查的越多。 这里，RAT中映射关系被覆盖了，并不代表寄存器已经空闲了，它可能还在被中间的指令所使用，例如，指令C的源寄存器如果是r0，r0在重命名阶段已经被分配了一个寄存器，只是这个对应关系没有被写入RAT， 对写ROB进行检查 每一条指令都需要从RAT中读出之前对应的物理寄存器，并写到ROB的pPReg中。 在写ROB的时候，也同样需要对相关性进行检测 在RAT中，映射关系已经建立，而ROB中写入是为了管理Free List 例如，在上面这条指令D要写ROB时，应该采用指令B的P31，而不是从RAT读出r0之前对应的寄存器。 在写ROB的过程是并行的，寄存器重命名阶段也会写ROB！！ 对于指令B，其pPreg的值应该来自指令A映射的P30 对于指令D，其pPreg的值应该来自指令B映射的P31 实现过程中的一些要点 需要采用读优先的RAM，因为需要先读出旧的映射关系，才能写入新的映射关系。 有的指令没有目的寄存器，有的指令源操作数是立即数，需要对这些指令进行标记，并决定从Free List中读取数值的个数。 使用目的寄存器读取RAT时，目的寄存器不存在的指令不读取RAT，也不改写RAT（不需要分配寄存器） 使用源寄存器读取RAT时，如果源寄存器不存在，直接忽略从RAT读取的结果即可 7.5 寄存器重命名过程的恢复 流水线中的指令都处于推测执行的状态（speculative） 指令在离开流水线（退休）之前，都可能被抹掉 如何对已经占用的资源（分配的物理寄存器等）进行恢复？ CheckPoint WALK Architecture State 7.5.1 CheckPoint将32个寄存器的对应关系原样保存下来。 分为随机访问的Checkpoint和串行访问的Checkpoint 串行访问的Checkpoint需要多个周期才可以恢复 这类的设计需要从电路的层面进行实现，在FPGA上比较难实现 所以用cRAT实现的Checkpoint比较适用于FPGA 7.5.2 使用WALK 利用ROB中存储的信息，进行逐条恢复 例如，发现一条分支指令预测失败时，使用这条分支指令的编号，把流水线中相关的都抹去，从ROB的末端（最新的指令）开始，逐条将每条指令之前对应的映射关系写回到RAT中。 在正确路径上的指令，会在ROB中提交 需要逐个指令恢复 使用Checkpoint对分支预测失败进行恢复，使用WALK对异常进行恢复 7.5.3 使用Architectural State 使用2个不同的RAT，只有指令的结果提交后，才能在Architectural RAT中看到映射关系，其他的映射关系都只能在Speculative RAT中看到。 当发现分支预测失败或异常发生时，等待这条指令变成ROB中最旧的指令，然后将Architecture RAT复制到Speculative RAT中。","tags":[{"name":"Architecture","slug":"Architecture","permalink":"http://blog.hubohan.me/tags/Architecture/"}]},{"title":"Crosscutting Issues","date":"2019-08-24T22:57:13.000Z","path":"2019/08/24/Crosscutting-Issues/","text":"RISC Instruction Sets and Efficiency of Pipelining Suppose we need to add two values in memory and store them back. In some sophisticated ISA this will only take 1 instruction. In RISC, it will take 2 loads, an add, and a store. These instructions cannot be scheduled sequentially without intervening stalls Since in RISC instructions, the individual operations are seperate and can be individually scheduled by compiler or hardwares. Dynamically Scheduled Pipelines Simple pipelines fetch an instruction and issue it when there’s no data dependency between an instruction already in the pipeline and the instruction to be issued that cannot be hidden by bypassing or forwarding. Forwarding increase the latency of the circuit when there’s not a hazard Compiler can schedule the instructions to avoid the hazard ( called compiler or static scheduling ) All the techniques discussed so far use in-order issue. Check the dependency in ID If there’s a hazard, the pipeline will stall even if there are later instructions that are independent. out-of-order execution: seperate ID into 2 stages Issue Read Operands Dynamic Scheduling with a Scoreboard All instruction pass through the issue stage in order The can be stalled or bypass each other in the read operands stage Scoreboarding: allowing instructiosn to execute out of order when there are sufficient resources and no data dependences. The possible WAR hazards 1DIV.D F0, F2, F42ADD.D F10, F0, F83SUB.D F8, F8, F14 Antidependence between ADD.D and SUB.D SUB.D execute before ADD.D, then the source of ADD.D is destroyed. Likewise, WAW hazards will occur if the dest of SUB.D is F10 The goal of scoreboard is to maintain an execution rate of 1 IPC by execute an instruction as early as possible If one instruction is stalled, the other can be issued when there’s no dependence The detection and resolution of hazard are centralized in the scoreboard Every instruction goes into scoreboard, where the data dependence is recorded. The scoreboard will decide when the instruction can read operand and issue. The scoreboard will monitor the exection of every instructions. The scoreboard can decide whether an instruction can write to destination. 4 Steps in ExecutionThese 4 following steps will replace ID, EX and WB Issue a functional unit for the instruction is free and no other active instruction has the same destination When it is stalled, the instruction buffer will be filled. Read Operands a source operand is available if no earlier issued active instruction is going to write it This step, combined with issue step, completes the function of ID step in simple MIPS pipeline. Execution Write Back check the WAR hazard There is an instruction that has not read its operands that precedes the completing instruction( the instruction to be commit ) AND one of the operands is the same register as the result of the completing instruction It might be hard to distinguish the WAR and RAW Scoreboard does not take advantage of forwarding because the operands are read only when operands are available The penalty is not as large as we initially think There’s a limited number of source operand bus and result bus of register file so the scoreboard must guarantee the instruction in step 2 and 4 does not exceed the number of buses available. Scoreboard Data Structure Code Snippet 1L.D F6, 34(R2)2L.D F2, 45(R3)3MUL.D F0, F2, F44SUB.D F8, F6, F25DIV.D F10, F0, F66ADD.D F6, F8, F2 3 Parts of the Scoreboard Instruction Status : which step the instruction is in Functional unit status : the state of functional unit Busy Op Fi - Destination Fj, Fk - Source Qj, Qk - Functional Units producing source register Fj, Fk Rj, Rk - Flags indicating when Fj, Fk are ready and not yet read Register result status : which functional unit will write each register.","tags":[{"name":"Architecture","slug":"Architecture","permalink":"http://blog.hubohan.me/tags/Architecture/"}]},{"title":"MIPS流水线扩展：多周期操作","date":"2019-08-24T22:20:23.000Z","path":"2019/08/24/MIPS流水线扩展：多周期操作/","text":"MIPS流水线扩展：多周期操作 例如，浮点运算需要多个周期完成，EX周期可能会重复多次 在本节中，假定MIPS实现4个独立功能单元： 主整数单元 浮点与整数乘法器 浮点加法器 浮点与整数除法器 假定这些功能单元的执行级没有实现流水化，那么前一条指令离开EX之前，不会发射任何一条指令，以避免同时回写的结构性冒险 （图片） 事实上，可以流水化每一个功能部件，并允许多个指令同时进行。 定义功能单元的延迟以及启动间隔（重复间隔） 延迟：生成结果的指令和使用结果指令之间的周期数 启动间隔（重复间隔）：发出两个给定类型的操作之间必须间隔的周期数 改进的多配置流水线流水线的结构 在以下改进的流水线结构中，浮点乘法、加法被流水化，可以同时执行4个浮点加、7个浮点乘和1个浮点除。 就需要设立ID/EX, ID/M1, ID/DIV, ID/A1等寄存器 指令顺序发射，可以同时执行（不同的时钟周期） 可能出现的冒险 结构冒险：除法单元没有流水化，可能需要阻塞除法单元 结构冒险：可能会同时要求写入寄存器 指令提交顺序不同，可能出现WAW冒险 不会存在WAR冒险（先读后写，读出旧值） 异常不精确 RAW冒险会更加频繁：因为每一个操作的流水级变多，延迟变长，要等待的时钟周期变多了 冒险的类型复习： RAW, Read After Write, 表示写之后读出的才是正确的 WAR, Write After Read, 表示读之后写才是正确的 同时写寄存器的结构冒险的检测 跟踪ID级对于写端口的使用，在一条指令发射之前使其停顿：使用移位寄存器。这个寄存器指示任何已发射指令何时使用寄存器堆。如果待发射指令（ID中）和已发射指令需要同时使用，那么ID中的指令需要停顿一个周期，在每个时钟周期，这个寄存器会移动1位。这种方法在ID级检测了冲突 当一个冲突指令尝试进入MEM或者WB时，使其停顿。这样可能会导致多处Stall，还可能会导致EX, M7, A4, DIV同时被占用，stall返回流水线中 潜在的WAW冒险 仅仅发生在有一条无用的指令需要被执行的时候 但是仍然需要检测 解决方法 当检测到可能写同一个寄存器时，延迟后续指令的发射 检测冒险，丢弃前一条指令的结果 由于是顺序发射，所以可以检测已发射的指令写的寄存器是否和待发射的指令需要写的寄存器相同 冒险的检测 检测结构冒险：等待需要的功能单元不忙，并确认寄存器写不冲突 检测RAW冒险：原寄存器不是在已发射指令中的目的寄存器 检测WAW冒险 精确异常的处理问题描述考虑以下代码序列： 1DIV.D F0 F2 F42ADD.D F10 F10 F83SUB.D F12 F12 F14 指令顺序发射，但可能是乱序完成。 假设SUB.D引发了浮点运算异常，此时DIV.D还没有完成，ADD.D已经完成了（此处不存在冒险，允许乱序提交），此时可以通过清除流水线来实现。 然而如果DIV.D引发了异常，而ADD.D已经完成，此时难以恢复到异常发生之前的现场了。 解决方法 忍受不精确异常：某种异常不被允许，或是交给其他硬件处理，继续执行，或是加上单独测试异常的指令 缓存指令执行的结果，直到之前发射的指令完成：缓冲区可能很大，电路比较复杂 历史记录文件 未来文件 记录足够的信息，例如每一条指令对应的PC，使用中断处理程序来处理 假设有以下几条指令： $Inst_1$ - 耗时很长的指令，最终导致中断， $Inst_2-Inst_{n-1}$ - 还没完成的指令 $Inst_n$ - 已经完成的指令 给定流水线中所有的PC，软件可以已完成的指令1和n，软件必须在中断处理结束之后，继续完成$Inst_2$到$Inst_{n-1}$，此后才从中断程序返回$Inst_{n+1}$的操作 只有在执行阶段的所有指令都不会造成异常时，才可以继续发射指令 需要在EX级尽早确定是否会触发异常，减少等待时间 举例：MIPS R4000 流水线 IF 计算PC 初始化Cache访问 IS 访问Cache RF Cache命中检测 指令译码 寄存器访问 Hazard检测 EX 执行 DF 访问数据Cache DS 访问数据Cache TC 数据Cache命中检测 WB 回写 Branch-Likely指令 TBC","tags":[{"name":"Architecture","slug":"Architecture","permalink":"http://blog.hubohan.me/tags/Architecture/"}]},{"title":"Midterm 2 Review(2)","date":"2019-07-24T18:57:45.000Z","path":"2019/07/24/Midterm-2-Review-2/","text":"Factors that Decide the Cache PerformanceHIT TimeContributing Factors Cache Size Associativity Miss RateContributing Factors Memory access behaviour of the program Block size / Cache size / Cache Type ( associativity ) ![image-20190724192712638](/Users/hubohan/Library/Application Support/typora-user-images/image-20190724192712638.png) Miss PenaltyContributing Factors: How big is your memory hierarchy Small block size — Lower MP MultiLevel CacheL1 Cache has the lowest hit time, and L2 / L3 focus on low miss rate L1 does not care about high hit rate AMAT = L1 HR + L1 MR * L1 MP L1 MP = L2 HR + L2 MR * L2 MP L2 Local Miss Rate = L2 Miss / L1 Miss Global Miss Rate = Products of all (higher) Local Miss Rate For example, global L2 miss rate = MRLocal L1 * MRLocalL2 Support/typora-user-images/image-20190724200304673.png Support/typora-user-images/image-20190724200322133.png TO BE Done: Example 1 and 2","tags":[{"name":"CS61C","slug":"CS61C","permalink":"http://blog.hubohan.me/tags/CS61C/"}]},{"title":"MidTerm 2 Review (1)","date":"2019-07-23T22:57:13.000Z","path":"2019/07/23/MidTerm-2-Review-1/","text":"Cache IntroductionPrinciple of Locality Example: Library Code, Stack, Array: Data are organized tightly together Temporal Locality (locality in time)If a memory location is referenced then it will tend to be referenced again soon Spatial Locality (locality in space)If a memory location is referenced, the locations with nearby addresses will tend to be referenced soon Cache Management TIO =&gt; TAG / INDEX / OFFSET Valid Bit Cache Params: Block Size(K) and Cache Size(C) Index may be block number, or group number(in associative ways) Block Replacement PolicyRandom ReplacementLRULeast Recently Used Cache Implementation Actual Data Block Tag Bits Valid Bit LRU Bits: 00 - Used Last 11 - Ready to remove Consistency Between Cache and MemWrite Hit Write Through: Write data to both mem and cache ( slower ) Include a write buffer that will update the mem parallel Write Back: if the block is in cache, update it only in cache, and mark it use a dirty bit to record whether it is modified Read Miss fectch data and stall the pipeline, then recover Write Miss Always have to update the block in the memory Update the cache or not? Write Allocate Bring a block into cache after a read miss Always pair with Write Back E.g. Accessing the same memory address many times -&gt; cache it No Write Allocate Always pair with Write Through E.g. Random writes ( don’t care about the caching ) Cache MappingDirect-Mapped Each memory block is mapped excatly to one slot in the cache the Hash function is deterministic Just need to check one slot Faster! But access bahaviour might leave some slot blank Byte X, Byte X + Cache Size, Byte X + n * Cache Size will be mapped into the same block Will cause conflicts TIO Address format T - Tag I: Index - determined by number of blocks O: offset - determined by block size the WORST CASE of DM consider that the cache size(C) = 16 access 0 -&gt; 16 -&gt; 0 -&gt; 32 -&gt; n*16 Only use one slot and cause every access MISS Set Associative Divide cache into sets, each of which consists of N blocks N is the associativity the Index refers to the group num $$ I = log_2 (C/KN)$$ the WORST CASE of SA with LRU: repeat pattern that at least N+1 map into the same set E.g N = 2, use the pattern 0, 8, 16 *Question: which block will be mapped into the same group? * Cache Performance Miss Rate and Miss Penalty Average Memeory Access Time: AMAT AMAT = HIT Time + Miss Rate * Miss Penalty Increase in hit rate ( cache size ) will increase the hit time, which will overcome the improvement for hit rate, decrease the performance Source of Cache Misses: 3Cs Item Explain Solution Effect Compulsory the first time to reference must cause miss Increase the block size Increase MP; too large block increase MR Capacity can’t hold all blocks in a set Increase the cache size Increase the HT Conflict different address mapped into the same location ( Lack of associativity ) Increase associativity Increase the HT","tags":[{"name":"CS61C Exams","slug":"CS61C-Exams","permalink":"http://blog.hubohan.me/tags/CS61C-Exams/"}]}]