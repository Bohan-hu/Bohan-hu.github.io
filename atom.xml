<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Robert Hu</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.hubohan.me/"/>
  <updated>2020-11-25T02:24:55.845Z</updated>
  <id>http://blog.hubohan.me/</id>
  
  <author>
    <name>Bohan Hu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>几种寄存器重命名技术</title>
    <link href="http://blog.hubohan.me/2019/09/24/Register_rename/"/>
    <id>http://blog.hubohan.me/2019/09/24/Register_rename/</id>
    <published>2019-09-24T19:45:28.000Z</published>
    <updated>2020-11-25T02:24:55.845Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第七章：寄存器重命名"><a href="#第七章：寄存器重命名" class="headerlink" title="第七章：寄存器重命名"></a>第七章：寄存器重命名</h1><h2 id="7-1-概述"><a href="#7-1-概述" class="headerlink" title="7.1 概述"></a>7.1 概述</h2><ul><li>数据相关性中，只有RAW是真相关，其他的可以通过不同的寄存器名字解决</li></ul><hr><p>WAW相关</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">R1 &#x3D; R2 + R3</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">R1 &#x3D; R4 * R5</span></pre></td></tr></table></figure><p>可以改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">R1 &#x3D; R2 + R3</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">R6 &#x3D; R4 * R5</span></pre></td></tr></table></figure><hr><p>WAR相关</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">R1 &#x3D; R2 * R3</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">R2 &#x3D; R4 + R5</span></pre></td></tr></table></figure><p>可以改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">R1 &#x3D; R2 * R3</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">R6 &#x3D; R4 + R5</span></pre></td></tr></table></figure><hr><p>寄存器重命名的原因</p><ul><li>个数有限</li><li>程序中的循环体：不断地向某个寄存器写入，会导致大量WAW相关</li><li>代码重用：一段代码被重复调用，导致WAW相关</li></ul><hr><img src="第七章：寄存器重命名.assets/1567604318078.png" alt="1567604318078" style="zoom:67%;" /><p>动态的寄存器重命名，消除WAW和WAR冒险。</p><p>重命名映射表可以通过SRAM或CAM来实现。</p><h2 id="7-2-寄存器重命名的方式"><a href="#7-2-寄存器重命名的方式" class="headerlink" title="7.2 寄存器重命名的方式"></a>7.2 寄存器重命名的方式</h2><p>（1）将逻辑寄存器ARF扩展来实现重命名</p><p>（2）使用统一的物理寄存器PRF来实现重命名</p><p>（3）使用ROB来实现重命名</p><p>三种方法的本质都是把逻辑寄存器映射到物理寄存器上面。</p><hr><p>设计考虑的问题</p><p>（1）什么时候占用物理寄存器？寄存器来自哪里？</p><p>（2）什么时候释放物理寄存器？寄存器去向何处？</p><p>（3）分支预测失败，如何处理？</p><p>（4）发生异常，如何处理？</p><h3 id="7-2-1-使用ROB进行寄存器重命名"><a href="#7-2-1-使用ROB进行寄存器重命名" class="headerlink" title="7.2.1 使用ROB进行寄存器重命名"></a>7.2.1 使用ROB进行寄存器重命名</h3><ul><li><p>当一条指令被写入ROB一个项时，这个项在ROB中的编号就是这条指令的<strong>目的寄存器</strong>对应的物理寄存器。（映射关系）</p></li><li><p>逻辑寄存器中存的是最新的值</p></li><li><p>还需要一个映射表来判断当前ARF的值是否最新，<strong>应该从ARF中取值还是从PRF中取值？</strong>（如果ROB中有写R1的指令，那么就需要从ROB中找到R1的值，因为此时ARF中的值不是最新的）</p><img src="第七章：寄存器重命名.assets/1567605282604.png" alt="1567605282604" style="zoom: 33%;" /></li><li><p>如果一个逻辑寄存器的值还在ROB中，则RRT会给出这个寄存器在ROB中的编号</p></li><li><p>如果指令提交，则这一项会被标记</p></li><li><p>缺点：增加了ROB读的复杂性，且操作数可能来自ROB，也可能来自ARF</p></li></ul><h3 id="7-2-2-将ARF扩展进行寄存器重命名"><a href="#7-2-2-将ARF扩展进行寄存器重命名" class="headerlink" title="7.2.2 将ARF扩展进行寄存器重命名"></a>7.2.2 将ARF扩展进行寄存器重命名</h3><p>引入PRF（FIFO），当指令要写寄存器时，分配一个项，在映射表中记录地址，当指令要提交时，则释放在FIFO中的空间，并写回ARF。</p><p>也需要一个映射表。</p><img src="第七章：寄存器重命名.assets/1567606538227.png" alt="1567606538227" style="zoom: 40%;" /><p>一个逻辑寄存器的值在其生命周期内，仍然可能存在于PRF与ARF两个地方。</p><h3 id="7-2-3-使用统一PRF进行寄存器重命名"><a href="#7-2-3-使用统一PRF进行寄存器重命名" class="headerlink" title="7.2.3 使用统一PRF进行寄存器重命名"></a>7.2.3 使用统一PRF进行寄存器重命名</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="第七章：寄存器重命名.assets/1567606936444.png" alt="1567606936444" title="">                </div>                <div class="image-caption">1567606936444</div>            </figure><ul><li>PRF中存储了所有<strong>推测的(speculative)和正确的(retire)的</strong>寄存器值</li><li>物理寄存器的个数多于指令集中定义的逻辑寄存器的个数</li><li>在PRF中<ul><li>没有和指令产生映射关系的寄存器：Free</li><li>使用一个Free list来记录哪些寄存器空闲</li></ul></li><li>若一条指令被寄存器重命名，且存在目的寄存器，就会占据PRF中的一个寄存器，就不在Free list里了</li><li>被占用的寄存器有3个不同状态<ul><li>值未计算出来</li><li>值计算出来了，但没有提交</li><li>已经提交</li></ul></li><li>需要一个映射表，存储逻辑寄存器映射到物理寄存器的关系</li><li>Free List可以用FIFO实现（四端口，因为要取出4条指令，最多要重命名4个目的寄存器）</li><li>在寄存器重命名阶段（此时不考虑存在相关性问题）<ul><li>源寄存器：查映射表，得到真实地址</li><li>目的寄存器：查Free List，进行重命名</li></ul></li></ul><hr><ul><li>一条指令只有在retire（提交）后，才可以被外部看到，才是正确的</li><li>需要使用另外一个RAT，用以存储<strong>已经提交的指令</strong>和物理寄存器之间的关系！</li><li>这个在后面的寄存器重命名恢复过程中，会用得到</li><li>提交的时候写这个RAT，称为Architectural RAT</li><li>重命名时，读取的RAT时Speculative RAT，因为Spec RAT是最新的，考虑到所有正在执行的指令</li></ul><hr><ul><li>一个物理寄存器不再被后面指令使用时，就变成空闲状态，<strong>但如何才能知道后续指令是否还会使用这个物理寄存器呢</strong>？？</li><li><em>之前的理解错误，认为只要提交了指令，就可以释放这个物理寄存器。</em></li><li>一个保守的方法：相同的逻辑寄存器被再次写入</li></ul><img src="第七章：寄存器重命名.assets/1567608998234.png" alt="1567608998234" style="zoom: 67%;" /><ul><li>指令b对r1进行再次写入，则指令b对应的p6将替代p1，p1可以被释放</li><li>因此，还需要存储它之前对应的物理存储器（之前普林斯顿课上的Previous preg)</li></ul><h2 id="7-3-重命名映射表"><a href="#7-3-重命名映射表" class="headerlink" title="7.3 重命名映射表"></a>7.3 重命名映射表</h2><p>重命名映射表（RAT）在实现层面上，有2中方式。一种是基于SRAM，一种是基于CAM。</p><ul><li><p>基于SRAM的需要多端口（或者直接使用寄存器）</p><ul><li>例如，有32个ARF，有64个PRF，就需要32*6bits大小的寄存器</li><li>使用ARF编号寻址PRF内容（ARF编号作为地址）</li></ul><img src="第七章：寄存器重命名.assets/1567840843982.png" alt="1567840843982" style="zoom: 50%;" /></li><li><p>基于CAM的映射表</p><ul><li>大小等于物理寄存器的个数</li><li>每个表项都存放逻辑寄存器的编号</li><li>有点类似于全相联</li><li>有Valid bit，比较方便用于CheckPoint的记录（相比SRAM）</li><li>使用ARF编号作为内容寻址PRF</li></ul><img src="第七章：寄存器重命名.assets/1567840824326.png" alt="1567840824326" style="zoom:50%;" /></li><li><p>在分支指令时，需要保存CheckPoint，对SRAM来说，相当于需要保存所有的寄存器，而对于CAM而言，只需要将V往右进行移位就可以了</p></li><li><p>基于CAM的映射表仍然需要一个free list来记录哪些物理寄存器是空闲的</p><ul><li>一个物理寄存器何时空闲？后续指令写入同一逻辑寄存器（pPreg[a] = preg[b])，此时就可以释放之前对应的物理寄存器</li><li>并不是有效位V为0就代表是空闲状态，有可能映射关系刚刚被覆盖</li><li>空闲状态的管理不需要cRAT的参与</li></ul></li></ul><h3 id="实例：使用CAM做寄存器重命名"><a href="#实例：使用CAM做寄存器重命名" class="headerlink" title="实例：使用CAM做寄存器重命名"></a>实例：使用CAM做寄存器重命名</h3><img src="第七章：寄存器重命名.assets/1567847511513.png" alt="1567847511513" style="zoom: 50%;" /><p>（1）在分支指令F进行寄存器重命名时，需要对cRAT进行Checkpoint的保存，此时cRAT的内容如下表所示。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="第七章：寄存器重命名.assets/1567847588448.png" alt="1567847588448" title="">                </div>                <div class="image-caption">1567847588448</div>            </figure><p>指令BDE都写寄存器r7，对每条指令的r7进行重命名。</p><ul><li><p>在指令E进行寄存器重命名之后，物理寄存器P14就建立了和r7的对应关系，之前的2个映射关系全部无效（但不意味着这个物理寄存器现在空闲——<strong>如何理解？为什么不能用？</strong>P208一段话）</p></li><li><p>同时，有效位V全部被右移到了GC0进行备份</p></li></ul><p>（2）F执行完之后，发现分支预测错误</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="第七章：寄存器重命名.assets/1567848498900.png" alt="1567848498900" title="">                </div>                <div class="image-caption">1567848498900</div>            </figure><p>在对cRAT进行恢复之前，状态如上表所示。</p><ul><li><p>指令H重命名了r7，上面指令E对应的映射关系失效</p></li><li><p>分支指令F在预测失败后，进行状态恢复，将GC0的内容写到cRAT的有效位V，此时cRAT恢复到分支指令F进行寄存器重命名之前的状态。</p></li><li><p>指令B所占据的表项可能已经空闲，甚至被后续指令使用，但是恢复后，有效位变成了0.</p></li></ul><p>理论上，有几个checkpoint，就能允许有几条分支指令存在于流水线中。</p><hr><p>实例2：两条分支指令的情况：</p><img src="第七章：寄存器重命名.assets/1567940721480.png" alt="1567940721480" style="zoom:50%;" /><ul><li><p>第一条分支指令D对寄存器进行重命名时，保存状态到GC0</p><img src="第七章：寄存器重命名.assets/1567941278361.png" alt="1567941278361"  /></li></ul><img src="第七章：寄存器重命名.assets/1567941288923.png" alt="1567941288923" style="zoom: 50%;" /><p>其中，A的重命名映射关系被覆盖，此时V变成了0</p><ul><li>第二条分支指令G进行寄存器重命名时，继续对状态进行保存。此前，r9寄存器被重新命名了2次，导致E对应的映射关系被覆盖。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="第七章：寄存器重命名.assets/1567941425630.png" alt="1567941425630" title="">                </div>                <div class="image-caption">1567941425630</div>            </figure><ul><li>指令进行寄存器重命名完毕后，状态如下表所示：最后的HIJ指令覆盖了所有的映射关系</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="第七章：寄存器重命名.assets/1567941591354.png" alt="1567941591354" title="">                </div>                <div class="image-caption">1567941591354</div>            </figure><ul><li>此时，如果发现分支指令D预测错误，需要使用GC0对cRAT进行恢复，还要对free list进行恢复（读指针），并且清除此后所有的GC</li><li>（这个方法比较复杂，可以之后再研究，此时可以先弄清楚基于SRAM的重命名方式）</li></ul><h2 id="7-4-超标量处理器的寄存器重命名"><a href="#7-4-超标量处理器的寄存器重命名" class="headerlink" title="7.4 超标量处理器的寄存器重命名"></a>7.4 超标量处理器的寄存器重命名</h2><h3 id="一般步骤"><a href="#一般步骤" class="headerlink" title="一般步骤"></a>一般步骤</h3><p>对于<code>Dest = Src1 op Src2</code>的而言，</p><p>（1）从RAT中找到两个Src对应的物理寄存器PSrc（不同的扩展方式有不同的找法）</p><img src="第七章：寄存器重命名.assets/1567942033786.png" alt="1567942033786" style="zoom:50%;" /><p>（2）从Free List中找到一个空闲的物理寄存器Pdest，作为指令的目的寄存器</p><img src="第七章：寄存器重命名.assets/1567942045652.png" alt="1567942045652" style="zoom:50%;" /><p>（3）将逻辑寄存器Dest和物理寄存器PDest的映射关系写入重命名映射表RAT中。这样，使用Dest作为源寄存器的指令就可以正确寻址了。</p><img src="第七章：寄存器重命名.assets/1567942094000.png" alt="1567942094000" style="zoom:50%;" /><p>对应4 way超标量处理器而言，每周期对4条指令进行寄存器重命名。<strong>每条指令需要使用RAT的三个读端口，4条指令需要使用RAT的12个读端口，每条指令需要使用RAT的一个写端口</strong></p><img src="第七章：寄存器重命名.assets/1567942225455.png" alt="1567942225455" style="zoom:50%;" /><h3 id="同时重命名带来的相关性问题"><a href="#同时重命名带来的相关性问题" class="headerlink" title="同时重命名带来的相关性问题"></a>同时重命名带来的相关性问题</h3><p>还要考虑每个周期同时进行寄存器重命名的多条指令之间的相关性。</p><img src="第七章：寄存器重命名.assets/1567942273209.png" alt="1567942273209" style="zoom: 50%;" /><p>由于这四条指令是同时进行寄存器重命名的，会从RAT里读取信息，这样会造成错误的重命名，获取错误的数据。</p><p>（1）AB之间存在RAW相关，要先重命名r0，再从RAT读取r0对应的PR，不能同时</p><p>（2）ABD之间存在WAW，而再ROB中有保存指令对应的旧的映射关系，以方便指令退休时对旧的映射关系进行释放，因此，<strong>在记录旧的映射关系时，需要使用之前和他存在WAW相关的指令的映射关系，而不是从RAT读取的映射关系</strong>。例如，指令B将r0重命名为P31，旧的映射关系应该为P30，而不是从RAT读出的结果，由于几条指令是同时进行寄存器重命名的，所以需要注意这点。</p><p>（3）BD之间存在WAR相关，指令B读取r0，指令D写r0，这<em>问题不大</em>。</p><p>在超标量处理器设计中，寄存器重命名占用了大量的延迟，第一是SRAM多端口的延迟，第二是相关性处理造成的延迟。</p><blockquote><p>像这种情况，对于指令ABD存在的相关性问题，在下面的解决中，只允许指令D写入映射表，那指令A和B怎么办？指令B的源操作数是指令A的目的操作数，而指令A的映射关系又被指令D覆盖了。这是个问题吗？</p><p>第一步：读出原有的映射关系，这里指的是操作数原有的映射关系和目的寄存器原有的映射关系，这个映射关系位于，在上面的指令序列中，以第一条指令A为例，读出r0, r1, r2之前对应的物理寄存器，读出r0对应的物理寄存器是为了之后提交后能够释放原来的物理寄存器进入Free List。读出r1, r2的对应关系是为了从物理寄存器堆中取操作数。这一步是并行发生的，存在的问题可能就是在指令AB中存在RAW冒险，此时，需要采用给r0新分配的物理寄存器号P30，而不是原有的映射关系（原有的r0映射关系已经无效了，在后面会被覆盖，所以不能用）</p><p>第二步：解决WAW冒险。通过寄存器重命名，我们解决了WAW冒险，下一步修改RAT时，应该以最新的映射关系为准，也就是r0映射到P33。注意，这一步是为之后的指令服务的。在前面的几条指令中，r0被分别映射到了P30和P31，这个关系并没有在RAT中记录，因为我们已经读完了RAT，源操作数信息（对应的物理寄存器）已经就绪；写RAT，是为了后面的指令服务，这四条指令将不再读RAT的内容。</p><p>值得注意的是，指令AB中r0的映射关系不在RAT中记录，但是会在ROB中记录，在提交指令时，P30、P31会被逐个释放到自由列表。</p></blockquote><h3 id="7-4-1-解决RAW相关性（读原有的映射关系）"><a href="#7-4-1-解决RAW相关性（读原有的映射关系）" class="headerlink" title="7.4.1 解决RAW相关性（读原有的映射关系）"></a>7.4.1 解决RAW相关性（读原有的映射关系）</h3><ul><li>这一步主要是读出原有的映射关系</li><li>如果存在新分配的</li></ul><img src="第七章：寄存器重命名.assets/1567944297036.png" alt="1567944297036" style="zoom:50%;" /><p>上图表示的是不存在RAW相关性的寄存器重命名过程，而下图展示的是存在RAW相关性，但没有进行处理时，寄存器的重命名过程。</p><img src="第七章：寄存器重命名.assets/1567945260961.png" alt="1567945260961" style="zoom: 50%;" /><ul><li>在寄存器重命名阶段，指令的顺序还是in-order的，需要把<strong>每一条指令的源寄存器编号和前面所有指令的目的寄存器编号</strong>进行比较，如果存在一个相等的项，就从当前周期的Free List输出对应值，如果存在多个相等的项，就选择最新的那条指令。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="第七章：寄存器重命名.assets/1567945429229.png" alt="1567945429229" title="">                </div>                <div class="image-caption">1567945429229</div>            </figure><p><img src="%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D.assets/1567945702552.png" alt="1567945702552"></p><p>组内相关性检查的电路和访问RAT是并行工作的，不会对处理器的周期产生负面影响。</p><p>越后面的指令，需要的比较就越多。</p><h3 id="7-4-2-解决WAW相关性（写入）"><a href="#7-4-2-解决WAW相关性（写入）" class="headerlink" title="7.4.2 解决WAW相关性（写入）"></a>7.4.2 解决WAW相关性（写入）</h3><p>WAW相关性虽然对执行过程没有什么影响，但是对后续的ROB写入和寄存器的释放有影响。</p><hr><p><strong>对写RAT进行检查</strong></p><p>在重命名这个周期内，如果有多条指令的目的寄存器都相等，只有最新的映射关系才允许写入RAT。</p><img src="第七章：寄存器重命名.assets/1567946450941.png" alt="1567946450941" style="zoom: 50%;" /><p><strong>设置一个写使能信号：是否更新RAT？由于后续指令可能会覆盖，所以只允许一组存在WAW相关的指令中，最新的指令更新</strong></p><p>和上面相反的是，越靠前的指令需要检查的越多。</p><img src="第七章：寄存器重命名.assets/1567947188303.png" alt="1567947188303" style="zoom: 50%;" /><p>这里，RAT中映射关系被覆盖了，并不代表<strong>寄存器已经空闲了</strong>，它可能还在被<strong>中间的指令所使用</strong>，例如，指令C的源寄存器如果是r0，r0在重命名阶段已经被分配了一个寄存器，只是这个对应关系没有被写入RAT，</p><hr><p><strong>对写ROB进行检查</strong></p><ul><li><p>每一条指令都需要从RAT中读出之前对应的物理寄存器，并写到ROB的pPReg中。</p></li><li><p>在写ROB的时候，也同样需要对相关性进行检测</p></li><li><p>在RAT中，映射关系已经建立，而ROB中写入是为了管理Free List</p><img src="第七章：寄存器重命名.assets/1567950219247.png" alt="1567950219247" style="zoom: 67%;" /></li><li><p>例如，在上面这条指令D要写ROB时，应该采用指令B的P31，而不是从RAT读出r0之前对应的寄存器。</p></li><li><p>在写ROB的过程是并行的，寄存器重命名阶段也会写ROB！！</p></li></ul><blockquote><p>对于指令B，其pPreg的值应该来自指令A映射的P30</p><p>对于指令D，其pPreg的值应该来自指令B映射的P31</p></blockquote><img src="第七章：寄存器重命名.assets/1567954113858.png" alt="1567954113858" style="zoom: 33%;" /><p><strong>实现过程中的一些要点</strong></p><blockquote><ol><li>需要采用读优先的RAM，因为需要先读出旧的映射关系，才能写入新的映射关系。</li><li>有的指令没有目的寄存器，有的指令源操作数是立即数，需要对这些指令进行标记，并决定从Free List中读取数值的个数。</li><li>使用目的寄存器读取RAT时，目的寄存器不存在的指令不读取RAT，也不改写RAT（不需要分配寄存器）</li><li>使用源寄存器读取RAT时，如果源寄存器不存在，直接忽略从RAT读取的结果即可</li></ol></blockquote><h2 id="7-5-寄存器重命名过程的恢复"><a href="#7-5-寄存器重命名过程的恢复" class="headerlink" title="7.5 寄存器重命名过程的恢复"></a>7.5 寄存器重命名过程的恢复</h2><ul><li>流水线中的指令都处于推测执行的状态（speculative）</li><li>指令在离开流水线（退休）之前，都可能被抹掉</li><li>如何对已经占用的资源（分配的物理寄存器等）进行恢复？<ul><li>CheckPoint</li><li>WALK</li><li>Architecture State</li></ul></li></ul><h3 id="7-5-1-CheckPoint"><a href="#7-5-1-CheckPoint" class="headerlink" title="7.5.1 CheckPoint"></a>7.5.1 CheckPoint</h3><p>将32个寄存器的对应关系原样保存下来。</p><ul><li><p>分为随机访问的Checkpoint和串行访问的Checkpoint</p><p><img src="%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D.assets/1568024932136.png" alt="1568024932136"></p></li></ul><img src="第七章：寄存器重命名.assets/1568024975636.png" alt="1568024975636" style="zoom:80%;" /><ul><li>串行访问的Checkpoint需要多个周期才可以恢复</li><li>这类的设计需要从电路的层面进行实现，在FPGA上比较难实现</li><li>所以用cRAT实现的Checkpoint比较适用于FPGA</li></ul><h3 id="7-5-2-使用WALK"><a href="#7-5-2-使用WALK" class="headerlink" title="7.5.2 使用WALK"></a>7.5.2 使用WALK</h3><ul><li>利用ROB中存储的信息，进行逐条恢复</li></ul><blockquote><p>例如，发现一条分支指令预测失败时，使用这条分支指令的编号，把流水线中相关的都抹去，从ROB的末端（最新的指令）开始，逐条将每条指令之前对应的映射关系写回到RAT中。</p></blockquote><ul><li>在正确路径上的指令，会在ROB中提交</li><li>需要逐个指令恢复</li><li><strong>使用Checkpoint对分支预测失败进行恢复，使用WALK对异常进行恢复</strong></li></ul><h3 id="7-5-3-使用Architectural-State"><a href="#7-5-3-使用Architectural-State" class="headerlink" title="7.5.3 使用Architectural State"></a>7.5.3 使用Architectural State</h3><img src="第七章：寄存器重命名.assets/1568026110777.png" alt="1568026110777" style="zoom:50%;" /><p>使用2个不同的RAT，只有指令的结果提交后，才能在Architectural RAT中看到映射关系，其他的映射关系都只能在Speculative RAT中看到。</p><p>当发现分支预测失败或异常发生时，<strong>等待这条指令变成ROB中最旧的指令</strong>，然后将Architecture RAT复制到Speculative RAT中。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第七章：寄存器重命名&quot;&gt;&lt;a href=&quot;#第七章：寄存器重命名&quot; class=&quot;headerlink&quot; title=&quot;第七章：寄存器重命名&quot;&gt;&lt;/a&gt;第七章：寄存器重命名&lt;/h1&gt;&lt;h2 id=&quot;7-1-概述&quot;&gt;&lt;a href=&quot;#7-1-概述&quot; class=&quot;
      
    
    </summary>
    
    
    
      <category term="Architecture" scheme="http://blog.hubohan.me/tags/Architecture/"/>
    
  </entry>
  
  <entry>
    <title>Crosscutting Issues</title>
    <link href="http://blog.hubohan.me/2019/08/24/Crosscutting-Issues/"/>
    <id>http://blog.hubohan.me/2019/08/24/Crosscutting-Issues/</id>
    <published>2019-08-24T22:57:13.000Z</published>
    <updated>2020-11-25T02:24:55.845Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RISC-Instruction-Sets-and-Efficiency-of-Pipelining"><a href="#RISC-Instruction-Sets-and-Efficiency-of-Pipelining" class="headerlink" title="RISC Instruction Sets and Efficiency of Pipelining"></a>RISC Instruction Sets and Efficiency of Pipelining</h2><ul><li><p>Suppose we need to add two values in memory and store them back.</p><p>In some sophisticated ISA this will only take 1 instruction.</p><p>In RISC, it will take 2 loads, an add, and a store.</p><p><strong>These instructions cannot be scheduled sequentially without intervening stalls</strong></p></li><li><p>Since in RISC instructions, the individual operations are seperate and can be individually scheduled by compiler or hardwares.</p></li></ul><h2 id="Dynamically-Scheduled-Pipelines"><a href="#Dynamically-Scheduled-Pipelines" class="headerlink" title="Dynamically Scheduled Pipelines"></a>Dynamically Scheduled Pipelines</h2><ul><li>Simple pipelines fetch an instruction and issue it when there’s no data dependency between an instruction already in the pipeline and the instruction to be issued that cannot be hidden by bypassing or forwarding.</li><li>Forwarding increase the latency of the circuit when there’s not a hazard</li><li>Compiler can schedule the instructions to avoid the hazard ( called compiler or static scheduling )</li><li>All the techniques discussed so far use in-order issue. <ul><li>Check the dependency in ID</li><li>If there’s a hazard, the pipeline will stall <strong>even if there are later instructions that are independent</strong>.</li></ul></li><li>out-of-order execution: seperate ID into 2 stages<ul><li>Issue</li><li>Read Operands</li></ul></li></ul><h4 id="Dynamic-Scheduling-with-a-Scoreboard"><a href="#Dynamic-Scheduling-with-a-Scoreboard" class="headerlink" title="Dynamic Scheduling with a Scoreboard"></a>Dynamic Scheduling with a Scoreboard</h4><ul><li><p>All instruction pass through the issue stage in order</p></li><li><p>The can be <strong>stalled</strong> or <strong>bypass each other</strong> in the <strong>read operands</strong> stage</p></li><li><p>Scoreboarding: allowing instructiosn to execute out of order when there are sufficient resources and no data dependences.</p></li><li><p>The possible WAR hazards</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">DIV.D F0, F2, F4</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">ADD.D F10, F0, F8</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">SUB.D F8, F8, F14</span></pre></td></tr></table></figure><ul><li>Antidependence between <strong>ADD.D and SUB.D</strong> </li><li>SUB.D execute before ADD.D, then the source of ADD.D is destroyed.</li><li>Likewise, WAW hazards will occur if the dest of SUB.D is F10</li></ul><ul><li>The goal of scoreboard is to maintain an execution rate of 1 IPC by execute an instruction as early as possible</li><li><strong>If one instruction is stalled, the other can be issued when there’s no dependence</strong></li></ul><hr><p>The detection and resolution of hazard are centralized in the scoreboard</p><ul><li>Every instruction goes into scoreboard, where the data dependence is recorded. </li><li>The scoreboard will decide when the instruction can read operand and issue. </li><li>The scoreboard will monitor the exection of every instructions.</li><li>The scoreboard can decide whether an instruction can write to destination.</li></ul><hr><h5 id="4-Steps-in-Execution"><a href="#4-Steps-in-Execution" class="headerlink" title="4 Steps in Execution"></a>4 Steps in Execution</h5><p>These 4 following steps will replace ID, EX and WB</p><ol><li><p>Issue</p><p><strong>a functional unit for the instruction is free and no other active instruction has the same destination</strong></p><p>When it is stalled, the instruction buffer will be filled.</p></li><li><p>Read Operands</p><p>a source operand is available if no earlier issued active instruction is going to write it</p><p>This step, combined with issue step, completes the function of <strong>ID step</strong> in simple MIPS pipeline.</p></li><li><p>Execution</p></li><li><p>Write Back</p><p>check the WAR hazard     </p><ul><li><p>There is an instruction that has not read its operands that precedes the completing instruction( the instruction to be commit ) <strong>AND</strong></p></li><li><p>one of the operands is the same register as the result of the completing instruction</p></li><li><p><strong>It might be hard to distinguish the WAR and RAW</strong></p></li></ul></li></ol><hr><ul><li>Scoreboard does not take advantage of forwarding because the operands are read only when operands are available</li><li>The penalty is not as large as we initially think</li><li>There’s a limited number of source operand bus and result bus of register file so the scoreboard must guarantee the instruction in step 2 and 4 does not exceed the number of buses available.</li></ul><h4 id="Scoreboard-Data-Structure"><a href="#Scoreboard-Data-Structure" class="headerlink" title="Scoreboard Data Structure"></a>Scoreboard Data Structure</h4><ul><li><p>Code Snippet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">L.DF6, 34(R2)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">L.DF2, 45(R3)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">MUL.DF0, F2, F4</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">SUB.DF8, F6, F2</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">DIV.D F10, F0, F6</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">ADD.D F6, F8, F2</span></pre></td></tr></table></figure></li></ul><h4 id="3-Parts-of-the-Scoreboard"><a href="#3-Parts-of-the-Scoreboard" class="headerlink" title="3 Parts of the Scoreboard"></a>3 Parts of the Scoreboard</h4><ol><li><em>Instruction Status</em> : which step the <strong>instruction is in</strong></li><li><em>Functional unit status</em> : the state of <strong>functional unit</strong><ul><li>Busy</li><li>Op</li><li>Fi - Destination</li><li>Fj, Fk - Source</li><li>Qj, Qk - Functional Units producing source register Fj, Fk</li><li>Rj, Rk - Flags indicating when Fj, Fk are ready and not yet read</li></ul></li><li><em>Register result status</em> : which functional unit will write each <strong>register</strong>.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RISC-Instruction-Sets-and-Efficiency-of-Pipelining&quot;&gt;&lt;a href=&quot;#RISC-Instruction-Sets-and-Efficiency-of-Pipelining&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
    
    
      <category term="Architecture" scheme="http://blog.hubohan.me/tags/Architecture/"/>
    
  </entry>
  
  <entry>
    <title>MIPS流水线扩展：多周期操作</title>
    <link href="http://blog.hubohan.me/2019/08/24/MIPS%E6%B5%81%E6%B0%B4%E7%BA%BF%E6%89%A9%E5%B1%95%EF%BC%9A%E5%A4%9A%E5%91%A8%E6%9C%9F%E6%93%8D%E4%BD%9C/"/>
    <id>http://blog.hubohan.me/2019/08/24/MIPS%E6%B5%81%E6%B0%B4%E7%BA%BF%E6%89%A9%E5%B1%95%EF%BC%9A%E5%A4%9A%E5%91%A8%E6%9C%9F%E6%93%8D%E4%BD%9C/</id>
    <published>2019-08-24T22:20:23.000Z</published>
    <updated>2020-11-25T02:24:55.845Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MIPS流水线扩展：多周期操作"><a href="#MIPS流水线扩展：多周期操作" class="headerlink" title="MIPS流水线扩展：多周期操作"></a>MIPS流水线扩展：多周期操作</h1><ul><li>例如，浮点运算需要多个周期完成，EX周期可能会重复多次</li><li>在本节中，假定MIPS实现4个独立功能单元：<ul><li>主整数单元</li><li>浮点与整数乘法器</li><li>浮点加法器</li><li>浮点与整数除法器</li></ul></li><li>假定这些功能单元的执行级没有实现流水化，那么前一条指令离开EX之前，不会发射任何一条指令，以避免同时回写的结构性冒险</li><li>（图片）</li><li>事实上，可以流水化每一个功能部件，并允许多个指令同时进行。</li><li>定义功能单元的延迟以及启动间隔（重复间隔）<ul><li>延迟：生成结果的指令和使用结果指令之间的周期数</li><li>启动间隔（重复间隔）：发出两个给定类型的操作之间必须间隔的周期数</li></ul></li></ul><h2 id="改进的多配置流水线"><a href="#改进的多配置流水线" class="headerlink" title="改进的多配置流水线"></a>改进的多配置流水线</h2><h3 id="流水线的结构"><a href="#流水线的结构" class="headerlink" title="流水线的结构"></a>流水线的结构</h3><ul><li><p>在以下改进的流水线结构中，浮点乘法、加法被流水化，可以同时执行4个浮点加、7个浮点乘和1个浮点除。</p><p><img src="/Users/hubohan/Downloads/IMG_0838.jpg" alt="IMG_0838"></p></li><li><p>就需要设立ID/EX, ID/M1, ID/DIV, ID/A1等寄存器</p></li><li><p>指令顺序发射，可以同时执行（不同的时钟周期）</p></li></ul><h3 id="可能出现的冒险"><a href="#可能出现的冒险" class="headerlink" title="可能出现的冒险"></a>可能出现的冒险</h3><ul><li>结构冒险：除法单元没有流水化，可能需要阻塞除法单元</li><li>结构冒险：可能会同时要求写入寄存器</li><li>指令提交顺序不同，可能出现WAW冒险</li><li>不会存在WAR冒险（先读后写，读出旧值）</li><li>异常不精确</li><li>RAW冒险会更加频繁：因为每一个操作的流水级变多，延迟变长，要等待的时钟周期变多了</li></ul><blockquote><p>冒险的类型复习：</p><p>RAW, Read After Write, 表示写之后读出的<strong>才是正确的</strong></p><p>WAR, Write After Read, 表示读之后写才是正确的</p></blockquote><h4 id="同时写寄存器的结构冒险的检测"><a href="#同时写寄存器的结构冒险的检测" class="headerlink" title="同时写寄存器的结构冒险的检测"></a>同时写寄存器的结构冒险的检测</h4><ul><li>跟踪ID级对于写端口的使用，在一条指令发射之前使其停顿：使用移位寄存器。这个寄存器指示任何已发射指令何时使用寄存器堆。如果待发射指令（ID中）和已发射指令需要同时使用，那么ID中的指令需要停顿一个周期，在每个时钟周期，这个寄存器会移动1位。<strong>这种方法在ID级检测了冲突</strong></li><li>当一个冲突指令尝试进入MEM或者WB时，使其停顿。这样可能会导致多处Stall，还可能会导致EX, M7, A4, DIV同时被占用，stall返回流水线中</li></ul><h4 id="潜在的WAW冒险"><a href="#潜在的WAW冒险" class="headerlink" title="潜在的WAW冒险"></a>潜在的WAW冒险</h4><ul><li>仅仅发生在有一条无用的指令需要被执行的时候</li><li>但是仍然需要检测</li><li>解决方法<ul><li>当检测到可能写同一个寄存器时，延迟后续指令的发射</li><li>检测冒险，丢弃前一条指令的结果</li></ul></li><li>由于是顺序发射，所以可以检测已发射的指令写的寄存器是否和待发射的指令需要写的寄存器相同</li></ul><h3 id="冒险的检测"><a href="#冒险的检测" class="headerlink" title="冒险的检测"></a>冒险的检测</h3><ul><li>检测结构冒险：等待需要的功能单元不忙，并确认寄存器写不冲突</li><li>检测RAW冒险：原寄存器不是在已发射指令中的目的寄存器</li><li>检测WAW冒险</li></ul><h3 id="精确异常的处理"><a href="#精确异常的处理" class="headerlink" title="精确异常的处理"></a>精确异常的处理</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>考虑以下代码序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">DIV.D F0 F2 F4</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">ADD.D F10 F10 F8</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">SUB.D F12 F12 F14</span></pre></td></tr></table></figure><p>指令顺序发射，但可能是乱序完成。</p><p>假设SUB.D引发了浮点运算异常，此时DIV.D还没有完成，ADD.D已经完成了（此处不存在冒险，允许乱序提交），此时可以通过清除流水线来实现。</p><p>然而如果DIV.D引发了异常，而ADD.D已经完成，此时难以恢复到异常发生之前的现场了。</p><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><ul><li>忍受不精确异常：某种异常不被允许，或是交给其他硬件处理，继续执行，或是加上单独测试异常的指令</li><li>缓存指令执行的结果，直到之前发射的指令完成：缓冲区可能很大，电路比较复杂<ul><li>历史记录文件</li><li>未来文件</li></ul></li><li>记录足够的信息，例如每一条指令对应的PC，使用中断处理程序来处理<ul><li>假设有以下几条指令：<ul><li>$Inst_1$ - 耗时很长的指令，最终导致中断，</li><li>$Inst_2-Inst_{n-1}$ - 还没完成的指令</li><li>$Inst_n$ - 已经完成的指令</li></ul></li><li>给定流水线中所有的PC，软件可以已完成的指令1和n，软件必须在中断处理结束之后，继续完成$Inst_2$到$Inst_{n-1}$，此后才从中断程序返回$Inst_{n+1}$的操作</li></ul></li><li>只有在执行阶段的所有指令都不会造成异常时，才可以继续发射指令<ul><li>需要在EX级尽早确定是否会触发异常，减少等待时间</li></ul></li></ul><h1 id="举例：MIPS-R4000-流水线"><a href="#举例：MIPS-R4000-流水线" class="headerlink" title="举例：MIPS R4000 流水线"></a>举例：MIPS R4000 流水线</h1><ul><li><p>IF</p><ul><li>计算PC</li><li>初始化Cache访问</li></ul></li><li><p>IS</p><ul><li>访问Cache</li></ul></li><li><p>RF</p><ul><li>Cache命中检测</li><li>指令译码</li><li>寄存器访问</li><li>Hazard检测</li></ul></li><li><p>EX</p><ul><li>执行</li></ul></li><li><p>DF</p><ul><li>访问数据Cache</li></ul></li><li><p>DS</p><ul><li>访问数据Cache</li></ul></li><li><p>TC</p><ul><li>数据Cache命中检测</li></ul></li><li><p>WB</p><ul><li>回写</li></ul><hr></li><li><p>Branch-Likely指令</p></li><li><p>TBC</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MIPS流水线扩展：多周期操作&quot;&gt;&lt;a href=&quot;#MIPS流水线扩展：多周期操作&quot; class=&quot;headerlink&quot; title=&quot;MIPS流水线扩展：多周期操作&quot;&gt;&lt;/a&gt;MIPS流水线扩展：多周期操作&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;例如，浮点运算需要多个周
      
    
    </summary>
    
    
    
      <category term="Architecture" scheme="http://blog.hubohan.me/tags/Architecture/"/>
    
  </entry>
  
  <entry>
    <title>Midterm 2 Review(2)</title>
    <link href="http://blog.hubohan.me/2019/07/24/Midterm-2-Review-2/"/>
    <id>http://blog.hubohan.me/2019/07/24/Midterm-2-Review-2/</id>
    <published>2019-07-24T18:57:45.000Z</published>
    <updated>2020-11-25T02:24:55.845Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Factors-that-Decide-the-Cache-Performance"><a href="#Factors-that-Decide-the-Cache-Performance" class="headerlink" title="Factors that Decide the Cache Performance"></a>Factors that Decide the Cache Performance</h1><h2 id="HIT-Time"><a href="#HIT-Time" class="headerlink" title="HIT Time"></a>HIT Time</h2><h3 id="Contributing-Factors"><a href="#Contributing-Factors" class="headerlink" title="Contributing Factors"></a>Contributing Factors</h3><ul><li>Cache Size</li><li>Associativity</li></ul><h2 id="Miss-Rate"><a href="#Miss-Rate" class="headerlink" title="Miss Rate"></a>Miss Rate</h2><h3 id="Contributing-Factors-1"><a href="#Contributing-Factors-1" class="headerlink" title="Contributing Factors"></a>Contributing Factors</h3><ul><li><p>Memory access behaviour of the program</p></li><li><p>Block size / Cache size / Cache Type ( associativity )</p><p>![image-20190724192712638](/Users/hubohan/Library/Application Support/typora-user-images/image-20190724192712638.png)</p></li></ul><h2 id="Miss-Penalty"><a href="#Miss-Penalty" class="headerlink" title="Miss Penalty"></a>Miss Penalty</h2><p>Contributing Factors:</p><ul><li>How big is your memory hierarchy</li><li>Small block size — Lower MP</li></ul><h1 id="MultiLevel-Cache"><a href="#MultiLevel-Cache" class="headerlink" title="MultiLevel Cache"></a>MultiLevel Cache</h1><p>L1 Cache has the lowest hit time, and L2 / L3 focus on low miss rate </p><p>L1 does not care about high hit rate</p><p><code>AMAT = L1 HR + L1 MR * L1 MP</code></p><p><code>L1 MP = L2 HR + L2 MR * L2 MP</code></p><p><code>L2 Local Miss Rate = L2 Miss / L1 Miss</code></p><p><code>Global Miss Rate = Products of all (higher) Local Miss Rate</code></p><p>For example, global L2 miss rate = MRLocal L1 * MRLocalL2</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/Users/hubohan/Library/Application" alt="image-20190724200304673" title="Support/typora-user-images/image-20190724200304673.png">                </div>                <div class="image-caption">Support/typora-user-images/image-20190724200304673.png</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/Users/hubohan/Library/Application" alt="image-20190724200322133" title="Support/typora-user-images/image-20190724200322133.png">                </div>                <div class="image-caption">Support/typora-user-images/image-20190724200322133.png</div>            </figure><ul><li>TO BE Done: Example 1 and 2</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Factors-that-Decide-the-Cache-Performance&quot;&gt;&lt;a href=&quot;#Factors-that-Decide-the-Cache-Performance&quot; class=&quot;headerlink&quot; title=&quot;Factors th
      
    
    </summary>
    
    
    
      <category term="CS61C" scheme="http://blog.hubohan.me/tags/CS61C/"/>
    
  </entry>
  
  <entry>
    <title>MidTerm 2 Review (1)</title>
    <link href="http://blog.hubohan.me/2019/07/23/MidTerm-2-Review-1/"/>
    <id>http://blog.hubohan.me/2019/07/23/MidTerm-2-Review-1/</id>
    <published>2019-07-23T22:57:13.000Z</published>
    <updated>2020-11-25T02:24:55.845Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cache-Introduction"><a href="#Cache-Introduction" class="headerlink" title="Cache Introduction"></a>Cache Introduction</h2><h3 id="Principle-of-Locality"><a href="#Principle-of-Locality" class="headerlink" title="Principle of Locality"></a>Principle of Locality</h3><ul><li>Example: Library</li><li>Code, Stack, Array: Data are organized tightly together</li></ul><h4 id="Temporal-Locality-locality-in-time"><a href="#Temporal-Locality-locality-in-time" class="headerlink" title="Temporal Locality (locality in time)"></a>Temporal Locality (locality in time)</h4><p>If a memory location is referenced then it will tend to be referenced again soon</p><h4 id="Spatial-Locality-locality-in-space"><a href="#Spatial-Locality-locality-in-space" class="headerlink" title="Spatial Locality (locality in space)"></a>Spatial Locality (locality in space)</h4><p>If a memory location is referenced, the locations with nearby addresses will tend to be referenced soon</p><h2 id="Cache-Management"><a href="#Cache-Management" class="headerlink" title="Cache Management"></a>Cache Management</h2><ul><li>TIO =&gt; TAG / INDEX / OFFSET</li><li>Valid Bit</li><li>Cache Params: <strong>Block Size(K)</strong> and <strong>Cache Size(C)</strong></li><li>Index may be block number, or group number(in associative ways)</li></ul><h3 id="Block-Replacement-Policy"><a href="#Block-Replacement-Policy" class="headerlink" title="Block Replacement Policy"></a>Block Replacement Policy</h3><h4 id="Random-Replacement"><a href="#Random-Replacement" class="headerlink" title="Random Replacement"></a>Random Replacement</h4><h4 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h4><p>Least Recently Used</p><h3 id="Cache-Implementation"><a href="#Cache-Implementation" class="headerlink" title="Cache Implementation"></a>Cache Implementation</h3><ul><li>Actual Data Block</li><li>Tag Bits</li><li>Valid Bit</li><li>LRU Bits: 00 - Used Last 11 - Ready to remove</li></ul><h3 id="Consistency-Between-Cache-and-Mem"><a href="#Consistency-Between-Cache-and-Mem" class="headerlink" title="Consistency Between Cache and Mem"></a>Consistency Between Cache and Mem</h3><h4 id="Write-Hit"><a href="#Write-Hit" class="headerlink" title="Write Hit"></a>Write Hit</h4><ul><li><p>Write Through:</p><ul><li>Write data to both mem and cache ( slower ) </li><li>Include a write buffer that will update the mem parallel</li></ul></li><li><p>Write Back:</p><ul><li>if the block is in cache, update it only in cache, and mark it </li><li>use a dirty bit to record whether it is modified</li></ul></li></ul><h4 id="Read-Miss"><a href="#Read-Miss" class="headerlink" title="Read Miss"></a>Read Miss</h4><ul><li>fectch data and stall the pipeline, then recover </li></ul><h4 id="Write-Miss"><a href="#Write-Miss" class="headerlink" title="Write Miss"></a>Write Miss</h4><ul><li><p>Always have to update the block in the memory</p></li><li><p><em>Update the cache or not?</em></p></li><li><p>Write Allocate</p><ul><li>Bring a block into cache after a read miss</li><li>Always pair with <strong>Write Back</strong></li><li>E.g. Accessing the same memory address many times -&gt; cache it</li></ul></li><li><p>No Write Allocate </p><ul><li>Always pair with <strong>Write Through</strong></li><li>E.g. Random writes ( don’t care about the caching )</li></ul></li></ul><h2 id="Cache-Mapping"><a href="#Cache-Mapping" class="headerlink" title="Cache Mapping"></a>Cache Mapping</h2><h3 id="Direct-Mapped"><a href="#Direct-Mapped" class="headerlink" title="Direct-Mapped"></a>Direct-Mapped</h3><ul><li><p>Each memory block is mapped excatly to one slot in the cache </p></li><li><p>the Hash function is <strong>deterministic</strong></p></li><li><p>Just need to check <code>one slot</code></p></li><li><p>Faster!</p></li><li><p><strong>But access bahaviour might leave some slot blank</strong></p><ul><li>Byte X, Byte X + Cache Size, Byte X + n * Cache Size will be mapped into the same block</li><li>Will cause conflicts</li></ul></li><li><p><code>TIO</code> Address format</p><ul><li><code>T</code> - Tag </li><li><code>I</code>: Index - determined by <code>number of blocks</code></li><li><code>O</code>: offset - determined by <code>block size</code></li></ul></li><li><p><strong>the WORST CASE of DM</strong></p><ul><li>consider that the cache size(C) = 16</li><li>access 0 -&gt; 16 -&gt; 0 -&gt; 32 -&gt; n*16</li><li>Only use one slot and cause every access MISS</li></ul></li></ul><h3 id="Set-Associative"><a href="#Set-Associative" class="headerlink" title="Set Associative"></a>Set Associative</h3><ul><li><p>Divide cache into sets, each of which consists of N blocks </p></li><li><p>N is the <strong>associativity</strong></p></li><li><p>the Index refers to the group num</p></li><li><p>$$ I = log_2 (C/KN)$$</p><p><img src="/Users/hubohan/Library/Application%20Support/typora-user-images/image-20190723221429306.png" alt="image-20190723221429306"></p></li><li><p><strong>the WORST CASE of SA</strong></p><ul><li>with LRU: repeat pattern that at least N+1 map into the same set</li><li>E.g N = 2, use the pattern 0, 8, 16</li><li>*<em>Question: which block will be mapped into the same group? *</em></li></ul></li></ul><h2 id="Cache-Performance"><a href="#Cache-Performance" class="headerlink" title="Cache Performance"></a>Cache Performance</h2><ul><li>Miss Rate and Miss Penalty</li><li>Average Memeory Access Time: AMAT </li><li><strong>AMAT  = HIT Time + Miss Rate * Miss Penalty</strong></li><li>Increase in hit rate ( cache size ) will increase the hit time, which will overcome the improvement for hit rate, decrease the performance </li></ul><h3 id="Source-of-Cache-Misses-3Cs"><a href="#Source-of-Cache-Misses-3Cs" class="headerlink" title="Source of Cache Misses: 3Cs"></a>Source of Cache Misses: 3Cs</h3><table><thead><tr><th>Item</th><th>Explain</th><th>Solution</th><th>Effect</th></tr></thead><tbody><tr><td>Compulsory</td><td>the first time to reference must cause miss</td><td>Increase the block size</td><td>Increase MP; too large block <strong>increase MR</strong></td></tr><tr><td>Capacity</td><td>can’t hold all blocks in a set</td><td>Increase the cache size</td><td>Increase the HT</td></tr><tr><td>Conflict</td><td>different address mapped into the same location ( Lack of associativity )</td><td>Increase associativity</td><td>Increase the HT</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Cache-Introduction&quot;&gt;&lt;a href=&quot;#Cache-Introduction&quot; class=&quot;headerlink&quot; title=&quot;Cache Introduction&quot;&gt;&lt;/a&gt;Cache Introduction&lt;/h2&gt;&lt;h3 id=&quot;P
      
    
    </summary>
    
    
    
      <category term="CS61C Exams" scheme="http://blog.hubohan.me/tags/CS61C-Exams/"/>
    
  </entry>
  
</feed>
